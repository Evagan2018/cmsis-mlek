<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>MLEK - Audio Applications - Machine Learning Evaluation Kit (MLEK) for CMSIS Workflows</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="css/extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "MLEK - Audio Applications";
        var mkdocs_page_input_path = "templates_audio.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="index.html" class="icon icon-home"> Machine Learning Evaluation Kit (MLEK) for CMSIS Workflows
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="index.html">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">MLEK - Audio Applications</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#required-api-interfaces">Required API Interfaces</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#keyword-spotting-application">Keyword Spotting Application</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#audio-stream-preprocessing">Audio Stream Preprocessing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#micromet-ml-model">MicroMet ML Model</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#build-types">Build Types</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#audio-user-algorithm-template">Audio User Algorithm Template</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#working-with-mlek-templates">Working with MLEK Templates</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="templates_video.html">MLEK - Video Applications</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="target_configuration_refapp.html">Targeting Hardware Boards</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="target_configuration_avh.html">Targeting Arm Virtual Hardware</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Machine Learning Evaluation Kit (MLEK) for CMSIS Workflows</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html" class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">MLEK - Audio Applications</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/ARM-Examples/cmsis-mlek/edit/main/docs/templates_audio.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="mlek-audio-applications">MLEK - Audio Applications</h1>
<!-- markdownlint-disable MD013 -->
<!-- markdownlint-disable MD036 -->

<p>This chapter describes the MLEK reference applications for real-time audio processing:</p>
<ul>
<li><strong>Keyword Spotting (KWS)</strong>: Demonstrates wake word detection and voice command recognition</li>
<li><strong>Audio User Algorithm Template</strong>: Provides a foundation for custom audio ML processing applications</li>
</ul>
<h2 id="required-api-interfaces">Required API Interfaces</h2>
<p>For hardware deployment, the Board-Layer should provide the following API interfaces:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Required API Interface</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>CMSIS_VIO</strong></td>
<td style="text-align: left;">Virtual I/O interface for LEDs, buttons, and basic I/O</td>
</tr>
<tr>
<td style="text-align: left;"><strong>CMSIS_VSTREAM_AUDIO_IN</strong></td>
<td style="text-align: left;">Virtual Audio Input / Audio Interface</td>
</tr>
<tr>
<td style="text-align: left;"><strong>STDOUT, STDERR</strong></td>
<td style="text-align: left;">Standard output for printf debugging and logging</td>
</tr>
</tbody>
</table>
<p>These interfaces ideally are supplied by the vendor of your evaluation board. For custom hardware, details on the implementation are 
found in the <a href="https://arm-software.github.io/CMSIS_6/latest/Driver/group__vstream__interface__gr.html">CMSIS-Driver Manual</a></p>
<h2 id="keyword-spotting-application">Keyword Spotting Application</h2>
<p>Keyword spotting (KWS) reference application detects predefined words or phrases from a continuous audio stream. An embedded device can listen to a list of "wake words" and use it to execute commands. This implementation uses TensorFlow Lite Micro and CMSIS-NN for optimized inference on Cortex-M processors or Ethos-U processors.</p>
<p>How KWS works:</p>
<ul>
<li>Incoming audio is captured from a microphone or played back from a test sample.</li>
<li>The audio stream is preprocessed and converted into Mel-frequency cepstral coefficients (MFCC) features.</li>
<li>A MicroNet keyword spotting model classifies the MFCC features to determine which keyword, if any, was spoken.</li>
<li>Detection results are reported via printf messages.</li>
</ul>
<h3 id="audio-stream-preprocessing">Audio Stream Preprocessing</h3>
<p>The MicroNet keyword spotting model expects audio data to be preprocessed before performing an inference. This section is an overview of the feature extraction process used. First, the audio data is normalized to the range (-1, 1).</p>
<p>Mel-Frequency Cepstral Coefficients (MFCCs) are a common feature that is extracted from audio data and can
be used as input for machine learning tasks such as keyword spotting and speech recognition. For implementation
details, please refer <code>Mfcc.cc</code> and <code>Mfcc.hpp</code>. These files are part of the software component <code>ML Eval Kit:Common:API</code>.</p>
<p>Next, a window of 640 audio samples (40ms) is taken from the audio input. From these 640 samples, we calculate 10
MFCC features. The whole window is shifted to the right by 320 audio samples (20ms) and 10 new MFCC features are calculated. This process of shifting and calculating is repeated. For 1 second audio input, 49 windows that each have 10 MFCC features are calculated. These extracted features are quantized and an inference is performed.</p>
<p><img alt="KWS Preprocessing" src="images/KWS_preprocessing.png" /></p>
<h3 id="micromet-ml-model">MicroMet ML Model</h3>
<p>The KWS application uses the <a href="https://github.com/Arm-Examples/ML-zoo/tree/master/models/keyword_spotting/micronet_medium/tflite_int8">MicroNet Medium INT8</a> model that is trained for twelve keywords (see file <code>src/Labels.cpp</code>).</p>
<p>ToDo:
  - how to get scripts?
  - how to convert models?</p>
<p>A sample audio file containing the word "down" is provided for testing.</p>
<p>The picture below shows serial output from a hardware target, while the application detects the keyword "yes" on a microphone stream.</p>
<p><img alt="KWS_Console_Print" src="images/kws_print.png" /></p>
<h3 id="build-types">Build Types</h3>
<p>The KWS example defines four build types that control debug information and the audio source:</p>
<table>
<thead>
<tr>
<th>Build Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Debug-Live_Stream</strong></td>
<td>Uses live microphone input with debug information enabled.</td>
</tr>
<tr>
<td><strong>Release-Live_Stream</strong></td>
<td>Live microphone input with optimizations for performance.</td>
</tr>
<tr>
<td><strong>Debug-Data_Array</strong></td>
<td>Processes a built-in audio array for regression testing with debug information.</td>
</tr>
<tr>
<td><strong>Release-Data_Array</strong></td>
<td>Processes the audio array with release optimizations.</td>
</tr>
</tbody>
</table>
<p>Use the Debug build types during development and the Release build types for performance measurements. Switch between <em>Live_Stream</em> and <em>Data_Array</em> depending on whether you want real-time audio or a fixed sample. On Arm Virtual Hardware Targets, the Live_Stream is utilizing the VSI interface </p>
<h2 id="audio-user-algorithm-template">Audio User Algorithm Template</h2>
<p>Todo.</p>
<h2 id="working-with-mlek-templates">Working with MLEK Templates</h2>
<p>See Target Configuration chapters on how to deploy the reference applications to a specific hardware or simulation target. </p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="overview.html" class="btn btn-neutral float-left" title="Overview"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="templates_video.html" class="btn btn-neutral float-right" title="MLEK - Video Applications">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/ARM-Examples/cmsis-mlek" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="overview.html" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="templates_video.html" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
